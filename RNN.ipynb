{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "pOmtuISRat_Y",
        "outputId": "5fa1ca23-72fc-45d4-be2d-51e2285690af"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>_id</th>\n",
              "      <th>word</th>\n",
              "      <th>hand[0][0]</th>\n",
              "      <th>hand[0][1]</th>\n",
              "      <th>hand[0][2]</th>\n",
              "      <th>hand[0][3]</th>\n",
              "      <th>hand[0][4]</th>\n",
              "      <th>hand[1][0]</th>\n",
              "      <th>hand[1][1]</th>\n",
              "      <th>hand[1][2]</th>\n",
              "      <th>...</th>\n",
              "      <th>hand[60][0]</th>\n",
              "      <th>hand[60][1]</th>\n",
              "      <th>hand[60][2]</th>\n",
              "      <th>hand[60][3]</th>\n",
              "      <th>hand[60][4]</th>\n",
              "      <th>hand[61][0]</th>\n",
              "      <th>hand[61][1]</th>\n",
              "      <th>hand[61][2]</th>\n",
              "      <th>hand[61][3]</th>\n",
              "      <th>hand[61][4]</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>656e54ff24eed63bcf366d72</td>\n",
              "      <td>a</td>\n",
              "      <td>348.0</td>\n",
              "      <td>221.0</td>\n",
              "      <td>1019.0</td>\n",
              "      <td>619.0</td>\n",
              "      <td>1019.5</td>\n",
              "      <td>99.5</td>\n",
              "      <td>81.0</td>\n",
              "      <td>490.5</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>656e550424eed63bcf366d73</td>\n",
              "      <td>a</td>\n",
              "      <td>206.5</td>\n",
              "      <td>178.0</td>\n",
              "      <td>1018.0</td>\n",
              "      <td>500.5</td>\n",
              "      <td>1018.0</td>\n",
              "      <td>81.0</td>\n",
              "      <td>74.5</td>\n",
              "      <td>326.0</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>656e550b24eed63bcf366d74</td>\n",
              "      <td>a</td>\n",
              "      <td>829.0</td>\n",
              "      <td>1022.5</td>\n",
              "      <td>1020.0</td>\n",
              "      <td>720.0</td>\n",
              "      <td>1020.5</td>\n",
              "      <td>203.0</td>\n",
              "      <td>214.0</td>\n",
              "      <td>1018.0</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>656e550e24eed63bcf366d75</td>\n",
              "      <td>a</td>\n",
              "      <td>127.5</td>\n",
              "      <td>63.0</td>\n",
              "      <td>127.0</td>\n",
              "      <td>277.5</td>\n",
              "      <td>1015.5</td>\n",
              "      <td>50.5</td>\n",
              "      <td>35.0</td>\n",
              "      <td>89.5</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>656e551324eed63bcf366d76</td>\n",
              "      <td>a</td>\n",
              "      <td>84.5</td>\n",
              "      <td>65.5</td>\n",
              "      <td>170.5</td>\n",
              "      <td>252.0</td>\n",
              "      <td>1015.0</td>\n",
              "      <td>49.5</td>\n",
              "      <td>41.0</td>\n",
              "      <td>81.5</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>995</th>\n",
              "      <td>658f011987fcdffec11422d7</td>\n",
              "      <td>none</td>\n",
              "      <td>1021.5</td>\n",
              "      <td>839.5</td>\n",
              "      <td>918.5</td>\n",
              "      <td>964.5</td>\n",
              "      <td>1022.0</td>\n",
              "      <td>1018.0</td>\n",
              "      <td>426.5</td>\n",
              "      <td>837.0</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>996</th>\n",
              "      <td>658f012087fcdffec11422d8</td>\n",
              "      <td>none</td>\n",
              "      <td>1022.0</td>\n",
              "      <td>1022.0</td>\n",
              "      <td>883.5</td>\n",
              "      <td>905.0</td>\n",
              "      <td>1021.5</td>\n",
              "      <td>1019.0</td>\n",
              "      <td>776.5</td>\n",
              "      <td>885.0</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>997</th>\n",
              "      <td>658f012587fcdffec11422d9</td>\n",
              "      <td>none</td>\n",
              "      <td>1018.5</td>\n",
              "      <td>598.0</td>\n",
              "      <td>913.5</td>\n",
              "      <td>870.0</td>\n",
              "      <td>1018.0</td>\n",
              "      <td>1015.5</td>\n",
              "      <td>199.0</td>\n",
              "      <td>788.0</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>998</th>\n",
              "      <td>658f012b87fcdffec11422da</td>\n",
              "      <td>none</td>\n",
              "      <td>1014.0</td>\n",
              "      <td>300.0</td>\n",
              "      <td>714.0</td>\n",
              "      <td>931.5</td>\n",
              "      <td>1014.5</td>\n",
              "      <td>1014.0</td>\n",
              "      <td>162.0</td>\n",
              "      <td>629.0</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>999</th>\n",
              "      <td>658f013187fcdffec11422db</td>\n",
              "      <td>none</td>\n",
              "      <td>1021.0</td>\n",
              "      <td>848.5</td>\n",
              "      <td>795.0</td>\n",
              "      <td>916.0</td>\n",
              "      <td>1019.5</td>\n",
              "      <td>1018.5</td>\n",
              "      <td>609.0</td>\n",
              "      <td>835.0</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1000 rows × 312 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                          _id  word  hand[0][0]  hand[0][1]  hand[0][2]  \\\n",
              "0    656e54ff24eed63bcf366d72     a       348.0       221.0      1019.0   \n",
              "1    656e550424eed63bcf366d73     a       206.5       178.0      1018.0   \n",
              "2    656e550b24eed63bcf366d74     a       829.0      1022.5      1020.0   \n",
              "3    656e550e24eed63bcf366d75     a       127.5        63.0       127.0   \n",
              "4    656e551324eed63bcf366d76     a        84.5        65.5       170.5   \n",
              "..                        ...   ...         ...         ...         ...   \n",
              "995  658f011987fcdffec11422d7  none      1021.5       839.5       918.5   \n",
              "996  658f012087fcdffec11422d8  none      1022.0      1022.0       883.5   \n",
              "997  658f012587fcdffec11422d9  none      1018.5       598.0       913.5   \n",
              "998  658f012b87fcdffec11422da  none      1014.0       300.0       714.0   \n",
              "999  658f013187fcdffec11422db  none      1021.0       848.5       795.0   \n",
              "\n",
              "     hand[0][3]  hand[0][4]  hand[1][0]  hand[1][1]  hand[1][2]  ...  \\\n",
              "0         619.0      1019.5        99.5        81.0       490.5  ...   \n",
              "1         500.5      1018.0        81.0        74.5       326.0  ...   \n",
              "2         720.0      1020.5       203.0       214.0      1018.0  ...   \n",
              "3         277.5      1015.5        50.5        35.0        89.5  ...   \n",
              "4         252.0      1015.0        49.5        41.0        81.5  ...   \n",
              "..          ...         ...         ...         ...         ...  ...   \n",
              "995       964.5      1022.0      1018.0       426.5       837.0  ...   \n",
              "996       905.0      1021.5      1019.0       776.5       885.0  ...   \n",
              "997       870.0      1018.0      1015.5       199.0       788.0  ...   \n",
              "998       931.5      1014.5      1014.0       162.0       629.0  ...   \n",
              "999       916.0      1019.5      1018.5       609.0       835.0  ...   \n",
              "\n",
              "     hand[60][0]  hand[60][1]  hand[60][2]  hand[60][3]  hand[60][4]  \\\n",
              "0            NaN          NaN          NaN          NaN          NaN   \n",
              "1            NaN          NaN          NaN          NaN          NaN   \n",
              "2            NaN          NaN          NaN          NaN          NaN   \n",
              "3            NaN          NaN          NaN          NaN          NaN   \n",
              "4            NaN          NaN          NaN          NaN          NaN   \n",
              "..           ...          ...          ...          ...          ...   \n",
              "995          NaN          NaN          NaN          NaN          NaN   \n",
              "996          NaN          NaN          NaN          NaN          NaN   \n",
              "997          NaN          NaN          NaN          NaN          NaN   \n",
              "998          NaN          NaN          NaN          NaN          NaN   \n",
              "999          NaN          NaN          NaN          NaN          NaN   \n",
              "\n",
              "     hand[61][0]  hand[61][1]  hand[61][2]  hand[61][3]  hand[61][4]  \n",
              "0            NaN          NaN          NaN          NaN          NaN  \n",
              "1            NaN          NaN          NaN          NaN          NaN  \n",
              "2            NaN          NaN          NaN          NaN          NaN  \n",
              "3            NaN          NaN          NaN          NaN          NaN  \n",
              "4            NaN          NaN          NaN          NaN          NaN  \n",
              "..           ...          ...          ...          ...          ...  \n",
              "995          NaN          NaN          NaN          NaN          NaN  \n",
              "996          NaN          NaN          NaN          NaN          NaN  \n",
              "997          NaN          NaN          NaN          NaN          NaN  \n",
              "998          NaN          NaN          NaN          NaN          NaN  \n",
              "999          NaN          NaN          NaN          NaN          NaN  \n",
              "\n",
              "[1000 rows x 312 columns]"
            ]
          },
          "execution_count": 1,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models\n",
        "import pandas\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "mapping = {'a': [1,0,0,0,0,0,0,0,0,0],\n",
        "           'b': [0,1,0,0,0,0,0,0,0,0],\n",
        "           'c': [0,0,1,0,0,0,0,0,0,0],\n",
        "           'd': [0,0,0,1,0,0,0,0,0,0],\n",
        "           'e': [0,0,0,0,1,0,0,0,0,0],\n",
        "           'f': [0,0,0,0,0,1,0,0,0,0],\n",
        "           'g': [0,0,0,0,0,0,1,0,0,0],\n",
        "           'h': [0,0,0,0,0,0,0,1,0,0],\n",
        "           'i': [0,0,0,0,0,0,0,0,1,0],\n",
        "         'none':[0,0,0,0,0,0,0,0,0,1]}\n",
        "\n",
        "\n",
        "\n",
        "data = pandas.read_csv('./Data/Data.csv')\n",
        "\n",
        "data\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BZcqqXtjfEJa",
        "outputId": "d23a01f2-3531-427b-d724-5413acaf0008"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0         a\n",
              "1         a\n",
              "2         a\n",
              "3         a\n",
              "4         a\n",
              "       ... \n",
              "995    none\n",
              "996    none\n",
              "997    none\n",
              "998    none\n",
              "999    none\n",
              "Name: word, Length: 1000, dtype: object"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "words = data['word']\n",
        "y = data['word']\n",
        "\n",
        "words\n",
        "\n",
        "\n",
        "\n",
        "y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 444
        },
        "id": "lzeHWP3LfImh",
        "outputId": "0dfb5199-87a7-4098-f649-d2048b24cdd9"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>hand[0][0]</th>\n",
              "      <th>hand[0][1]</th>\n",
              "      <th>hand[0][2]</th>\n",
              "      <th>hand[0][3]</th>\n",
              "      <th>hand[0][4]</th>\n",
              "      <th>hand[1][0]</th>\n",
              "      <th>hand[1][1]</th>\n",
              "      <th>hand[1][2]</th>\n",
              "      <th>hand[1][3]</th>\n",
              "      <th>hand[1][4]</th>\n",
              "      <th>...</th>\n",
              "      <th>hand[60][0]</th>\n",
              "      <th>hand[60][1]</th>\n",
              "      <th>hand[60][2]</th>\n",
              "      <th>hand[60][3]</th>\n",
              "      <th>hand[60][4]</th>\n",
              "      <th>hand[61][0]</th>\n",
              "      <th>hand[61][1]</th>\n",
              "      <th>hand[61][2]</th>\n",
              "      <th>hand[61][3]</th>\n",
              "      <th>hand[61][4]</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>348.0</td>\n",
              "      <td>221.0</td>\n",
              "      <td>1019.0</td>\n",
              "      <td>619.0</td>\n",
              "      <td>1019.5</td>\n",
              "      <td>99.5</td>\n",
              "      <td>81.0</td>\n",
              "      <td>490.5</td>\n",
              "      <td>361.0</td>\n",
              "      <td>1016.5</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>206.5</td>\n",
              "      <td>178.0</td>\n",
              "      <td>1018.0</td>\n",
              "      <td>500.5</td>\n",
              "      <td>1018.0</td>\n",
              "      <td>81.0</td>\n",
              "      <td>74.5</td>\n",
              "      <td>326.0</td>\n",
              "      <td>203.0</td>\n",
              "      <td>1015.5</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>829.0</td>\n",
              "      <td>1022.5</td>\n",
              "      <td>1020.0</td>\n",
              "      <td>720.0</td>\n",
              "      <td>1020.5</td>\n",
              "      <td>203.0</td>\n",
              "      <td>214.0</td>\n",
              "      <td>1018.0</td>\n",
              "      <td>591.0</td>\n",
              "      <td>1019.0</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>127.5</td>\n",
              "      <td>63.0</td>\n",
              "      <td>127.0</td>\n",
              "      <td>277.5</td>\n",
              "      <td>1015.5</td>\n",
              "      <td>50.5</td>\n",
              "      <td>35.0</td>\n",
              "      <td>89.5</td>\n",
              "      <td>125.5</td>\n",
              "      <td>1015.5</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>84.5</td>\n",
              "      <td>65.5</td>\n",
              "      <td>170.5</td>\n",
              "      <td>252.0</td>\n",
              "      <td>1015.0</td>\n",
              "      <td>49.5</td>\n",
              "      <td>41.0</td>\n",
              "      <td>81.5</td>\n",
              "      <td>129.0</td>\n",
              "      <td>1014.5</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>995</th>\n",
              "      <td>1021.5</td>\n",
              "      <td>839.5</td>\n",
              "      <td>918.5</td>\n",
              "      <td>964.5</td>\n",
              "      <td>1022.0</td>\n",
              "      <td>1018.0</td>\n",
              "      <td>426.5</td>\n",
              "      <td>837.0</td>\n",
              "      <td>925.0</td>\n",
              "      <td>1017.0</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>996</th>\n",
              "      <td>1022.0</td>\n",
              "      <td>1022.0</td>\n",
              "      <td>883.5</td>\n",
              "      <td>905.0</td>\n",
              "      <td>1021.5</td>\n",
              "      <td>1019.0</td>\n",
              "      <td>776.5</td>\n",
              "      <td>885.0</td>\n",
              "      <td>902.5</td>\n",
              "      <td>1020.5</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>997</th>\n",
              "      <td>1018.5</td>\n",
              "      <td>598.0</td>\n",
              "      <td>913.5</td>\n",
              "      <td>870.0</td>\n",
              "      <td>1018.0</td>\n",
              "      <td>1015.5</td>\n",
              "      <td>199.0</td>\n",
              "      <td>788.0</td>\n",
              "      <td>823.5</td>\n",
              "      <td>1015.0</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>998</th>\n",
              "      <td>1014.0</td>\n",
              "      <td>300.0</td>\n",
              "      <td>714.0</td>\n",
              "      <td>931.5</td>\n",
              "      <td>1014.5</td>\n",
              "      <td>1014.0</td>\n",
              "      <td>162.0</td>\n",
              "      <td>629.0</td>\n",
              "      <td>893.0</td>\n",
              "      <td>1014.5</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>999</th>\n",
              "      <td>1021.0</td>\n",
              "      <td>848.5</td>\n",
              "      <td>795.0</td>\n",
              "      <td>916.0</td>\n",
              "      <td>1019.5</td>\n",
              "      <td>1018.5</td>\n",
              "      <td>609.0</td>\n",
              "      <td>835.0</td>\n",
              "      <td>877.5</td>\n",
              "      <td>1019.0</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1000 rows × 310 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "     hand[0][0]  hand[0][1]  hand[0][2]  hand[0][3]  hand[0][4]  hand[1][0]  \\\n",
              "0         348.0       221.0      1019.0       619.0      1019.5        99.5   \n",
              "1         206.5       178.0      1018.0       500.5      1018.0        81.0   \n",
              "2         829.0      1022.5      1020.0       720.0      1020.5       203.0   \n",
              "3         127.5        63.0       127.0       277.5      1015.5        50.5   \n",
              "4          84.5        65.5       170.5       252.0      1015.0        49.5   \n",
              "..          ...         ...         ...         ...         ...         ...   \n",
              "995      1021.5       839.5       918.5       964.5      1022.0      1018.0   \n",
              "996      1022.0      1022.0       883.5       905.0      1021.5      1019.0   \n",
              "997      1018.5       598.0       913.5       870.0      1018.0      1015.5   \n",
              "998      1014.0       300.0       714.0       931.5      1014.5      1014.0   \n",
              "999      1021.0       848.5       795.0       916.0      1019.5      1018.5   \n",
              "\n",
              "     hand[1][1]  hand[1][2]  hand[1][3]  hand[1][4]  ...  hand[60][0]  \\\n",
              "0          81.0       490.5       361.0      1016.5  ...          NaN   \n",
              "1          74.5       326.0       203.0      1015.5  ...          NaN   \n",
              "2         214.0      1018.0       591.0      1019.0  ...          NaN   \n",
              "3          35.0        89.5       125.5      1015.5  ...          NaN   \n",
              "4          41.0        81.5       129.0      1014.5  ...          NaN   \n",
              "..          ...         ...         ...         ...  ...          ...   \n",
              "995       426.5       837.0       925.0      1017.0  ...          NaN   \n",
              "996       776.5       885.0       902.5      1020.5  ...          NaN   \n",
              "997       199.0       788.0       823.5      1015.0  ...          NaN   \n",
              "998       162.0       629.0       893.0      1014.5  ...          NaN   \n",
              "999       609.0       835.0       877.5      1019.0  ...          NaN   \n",
              "\n",
              "     hand[60][1]  hand[60][2]  hand[60][3]  hand[60][4]  hand[61][0]  \\\n",
              "0            NaN          NaN          NaN          NaN          NaN   \n",
              "1            NaN          NaN          NaN          NaN          NaN   \n",
              "2            NaN          NaN          NaN          NaN          NaN   \n",
              "3            NaN          NaN          NaN          NaN          NaN   \n",
              "4            NaN          NaN          NaN          NaN          NaN   \n",
              "..           ...          ...          ...          ...          ...   \n",
              "995          NaN          NaN          NaN          NaN          NaN   \n",
              "996          NaN          NaN          NaN          NaN          NaN   \n",
              "997          NaN          NaN          NaN          NaN          NaN   \n",
              "998          NaN          NaN          NaN          NaN          NaN   \n",
              "999          NaN          NaN          NaN          NaN          NaN   \n",
              "\n",
              "     hand[61][1]  hand[61][2]  hand[61][3]  hand[61][4]  \n",
              "0            NaN          NaN          NaN          NaN  \n",
              "1            NaN          NaN          NaN          NaN  \n",
              "2            NaN          NaN          NaN          NaN  \n",
              "3            NaN          NaN          NaN          NaN  \n",
              "4            NaN          NaN          NaN          NaN  \n",
              "..           ...          ...          ...          ...  \n",
              "995          NaN          NaN          NaN          NaN  \n",
              "996          NaN          NaN          NaN          NaN  \n",
              "997          NaN          NaN          NaN          NaN  \n",
              "998          NaN          NaN          NaN          NaN  \n",
              "999          NaN          NaN          NaN          NaN  \n",
              "\n",
              "[1000 rows x 310 columns]"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "\n",
        "x = data.iloc[:,2:]\n",
        "x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 444
        },
        "id": "xyo_Gm-4fUqT",
        "outputId": "70a38067-8d49-4d44-83aa-0ae44d1fab43"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>hand[0][0]</th>\n",
              "      <th>hand[0][1]</th>\n",
              "      <th>hand[0][2]</th>\n",
              "      <th>hand[0][3]</th>\n",
              "      <th>hand[0][4]</th>\n",
              "      <th>hand[1][0]</th>\n",
              "      <th>hand[1][1]</th>\n",
              "      <th>hand[1][2]</th>\n",
              "      <th>hand[1][3]</th>\n",
              "      <th>hand[1][4]</th>\n",
              "      <th>...</th>\n",
              "      <th>hand[60][0]</th>\n",
              "      <th>hand[60][1]</th>\n",
              "      <th>hand[60][2]</th>\n",
              "      <th>hand[60][3]</th>\n",
              "      <th>hand[60][4]</th>\n",
              "      <th>hand[61][0]</th>\n",
              "      <th>hand[61][1]</th>\n",
              "      <th>hand[61][2]</th>\n",
              "      <th>hand[61][3]</th>\n",
              "      <th>hand[61][4]</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>348.0</td>\n",
              "      <td>221.0</td>\n",
              "      <td>1019.0</td>\n",
              "      <td>619.0</td>\n",
              "      <td>1019.5</td>\n",
              "      <td>99.5</td>\n",
              "      <td>81.0</td>\n",
              "      <td>490.5</td>\n",
              "      <td>361.0</td>\n",
              "      <td>1016.5</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>206.5</td>\n",
              "      <td>178.0</td>\n",
              "      <td>1018.0</td>\n",
              "      <td>500.5</td>\n",
              "      <td>1018.0</td>\n",
              "      <td>81.0</td>\n",
              "      <td>74.5</td>\n",
              "      <td>326.0</td>\n",
              "      <td>203.0</td>\n",
              "      <td>1015.5</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>829.0</td>\n",
              "      <td>1022.5</td>\n",
              "      <td>1020.0</td>\n",
              "      <td>720.0</td>\n",
              "      <td>1020.5</td>\n",
              "      <td>203.0</td>\n",
              "      <td>214.0</td>\n",
              "      <td>1018.0</td>\n",
              "      <td>591.0</td>\n",
              "      <td>1019.0</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>127.5</td>\n",
              "      <td>63.0</td>\n",
              "      <td>127.0</td>\n",
              "      <td>277.5</td>\n",
              "      <td>1015.5</td>\n",
              "      <td>50.5</td>\n",
              "      <td>35.0</td>\n",
              "      <td>89.5</td>\n",
              "      <td>125.5</td>\n",
              "      <td>1015.5</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>84.5</td>\n",
              "      <td>65.5</td>\n",
              "      <td>170.5</td>\n",
              "      <td>252.0</td>\n",
              "      <td>1015.0</td>\n",
              "      <td>49.5</td>\n",
              "      <td>41.0</td>\n",
              "      <td>81.5</td>\n",
              "      <td>129.0</td>\n",
              "      <td>1014.5</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>995</th>\n",
              "      <td>1021.5</td>\n",
              "      <td>839.5</td>\n",
              "      <td>918.5</td>\n",
              "      <td>964.5</td>\n",
              "      <td>1022.0</td>\n",
              "      <td>1018.0</td>\n",
              "      <td>426.5</td>\n",
              "      <td>837.0</td>\n",
              "      <td>925.0</td>\n",
              "      <td>1017.0</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>996</th>\n",
              "      <td>1022.0</td>\n",
              "      <td>1022.0</td>\n",
              "      <td>883.5</td>\n",
              "      <td>905.0</td>\n",
              "      <td>1021.5</td>\n",
              "      <td>1019.0</td>\n",
              "      <td>776.5</td>\n",
              "      <td>885.0</td>\n",
              "      <td>902.5</td>\n",
              "      <td>1020.5</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>997</th>\n",
              "      <td>1018.5</td>\n",
              "      <td>598.0</td>\n",
              "      <td>913.5</td>\n",
              "      <td>870.0</td>\n",
              "      <td>1018.0</td>\n",
              "      <td>1015.5</td>\n",
              "      <td>199.0</td>\n",
              "      <td>788.0</td>\n",
              "      <td>823.5</td>\n",
              "      <td>1015.0</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>998</th>\n",
              "      <td>1014.0</td>\n",
              "      <td>300.0</td>\n",
              "      <td>714.0</td>\n",
              "      <td>931.5</td>\n",
              "      <td>1014.5</td>\n",
              "      <td>1014.0</td>\n",
              "      <td>162.0</td>\n",
              "      <td>629.0</td>\n",
              "      <td>893.0</td>\n",
              "      <td>1014.5</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>999</th>\n",
              "      <td>1021.0</td>\n",
              "      <td>848.5</td>\n",
              "      <td>795.0</td>\n",
              "      <td>916.0</td>\n",
              "      <td>1019.5</td>\n",
              "      <td>1018.5</td>\n",
              "      <td>609.0</td>\n",
              "      <td>835.0</td>\n",
              "      <td>877.5</td>\n",
              "      <td>1019.0</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1000 rows × 310 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "     hand[0][0]  hand[0][1]  hand[0][2]  hand[0][3]  hand[0][4]  hand[1][0]  \\\n",
              "0         348.0       221.0      1019.0       619.0      1019.5        99.5   \n",
              "1         206.5       178.0      1018.0       500.5      1018.0        81.0   \n",
              "2         829.0      1022.5      1020.0       720.0      1020.5       203.0   \n",
              "3         127.5        63.0       127.0       277.5      1015.5        50.5   \n",
              "4          84.5        65.5       170.5       252.0      1015.0        49.5   \n",
              "..          ...         ...         ...         ...         ...         ...   \n",
              "995      1021.5       839.5       918.5       964.5      1022.0      1018.0   \n",
              "996      1022.0      1022.0       883.5       905.0      1021.5      1019.0   \n",
              "997      1018.5       598.0       913.5       870.0      1018.0      1015.5   \n",
              "998      1014.0       300.0       714.0       931.5      1014.5      1014.0   \n",
              "999      1021.0       848.5       795.0       916.0      1019.5      1018.5   \n",
              "\n",
              "     hand[1][1]  hand[1][2]  hand[1][3]  hand[1][4]  ...  hand[60][0]  \\\n",
              "0          81.0       490.5       361.0      1016.5  ...          NaN   \n",
              "1          74.5       326.0       203.0      1015.5  ...          NaN   \n",
              "2         214.0      1018.0       591.0      1019.0  ...          NaN   \n",
              "3          35.0        89.5       125.5      1015.5  ...          NaN   \n",
              "4          41.0        81.5       129.0      1014.5  ...          NaN   \n",
              "..          ...         ...         ...         ...  ...          ...   \n",
              "995       426.5       837.0       925.0      1017.0  ...          NaN   \n",
              "996       776.5       885.0       902.5      1020.5  ...          NaN   \n",
              "997       199.0       788.0       823.5      1015.0  ...          NaN   \n",
              "998       162.0       629.0       893.0      1014.5  ...          NaN   \n",
              "999       609.0       835.0       877.5      1019.0  ...          NaN   \n",
              "\n",
              "     hand[60][1]  hand[60][2]  hand[60][3]  hand[60][4]  hand[61][0]  \\\n",
              "0            NaN          NaN          NaN          NaN          NaN   \n",
              "1            NaN          NaN          NaN          NaN          NaN   \n",
              "2            NaN          NaN          NaN          NaN          NaN   \n",
              "3            NaN          NaN          NaN          NaN          NaN   \n",
              "4            NaN          NaN          NaN          NaN          NaN   \n",
              "..           ...          ...          ...          ...          ...   \n",
              "995          NaN          NaN          NaN          NaN          NaN   \n",
              "996          NaN          NaN          NaN          NaN          NaN   \n",
              "997          NaN          NaN          NaN          NaN          NaN   \n",
              "998          NaN          NaN          NaN          NaN          NaN   \n",
              "999          NaN          NaN          NaN          NaN          NaN   \n",
              "\n",
              "     hand[61][1]  hand[61][2]  hand[61][3]  hand[61][4]  \n",
              "0            NaN          NaN          NaN          NaN  \n",
              "1            NaN          NaN          NaN          NaN  \n",
              "2            NaN          NaN          NaN          NaN  \n",
              "3            NaN          NaN          NaN          NaN  \n",
              "4            NaN          NaN          NaN          NaN  \n",
              "..           ...          ...          ...          ...  \n",
              "995          NaN          NaN          NaN          NaN  \n",
              "996          NaN          NaN          NaN          NaN  \n",
              "997          NaN          NaN          NaN          NaN  \n",
              "998          NaN          NaN          NaN          NaN  \n",
              "999          NaN          NaN          NaN          NaN  \n",
              "\n",
              "[1000 rows x 310 columns]"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "\n",
        "data.iloc[:,2:]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "tdQcG_uHHQ2j"
      },
      "outputs": [
        {
          "ename": "KeyError",
          "evalue": "0",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "File \u001b[1;32mc:\\Python311\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3653\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3652\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 3653\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3654\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
            "File \u001b[1;32mc:\\Python311\\Lib\\site-packages\\pandas\\_libs\\index.pyx:147\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
            "File \u001b[1;32mc:\\Python311\\Lib\\site-packages\\pandas\\_libs\\index.pyx:176\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
            "File \u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi:7080\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
            "File \u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi:7088\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
            "\u001b[1;31mKeyError\u001b[0m: 0",
            "\nThe above exception was the direct cause of the following exception:\n",
            "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[13], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m data\u001b[38;5;241m.\u001b[39mshape\n\u001b[1;32m----> 3\u001b[0m \u001b[43mdata\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m      5\u001b[0m \u001b[38;5;66;03m# p.append(309)\u001b[39;00m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;66;03m# p.append(309)\u001b[39;00m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;66;03m# len(p)\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[38;5;66;03m# std_deviation = np.std(p)\u001b[39;00m\n\u001b[0;32m     17\u001b[0m \u001b[38;5;66;03m# print(std_deviation, \" \", average)\u001b[39;00m\n",
            "File \u001b[1;32mc:\\Python311\\Lib\\site-packages\\pandas\\core\\frame.py:3761\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3759\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m   3760\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_multilevel(key)\n\u001b[1;32m-> 3761\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3762\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[0;32m   3763\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m [indexer]\n",
            "File \u001b[1;32mc:\\Python311\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3655\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3653\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine\u001b[38;5;241m.\u001b[39mget_loc(casted_key)\n\u001b[0;32m   3654\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[1;32m-> 3655\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[0;32m   3656\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[0;32m   3657\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[0;32m   3658\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[0;32m   3659\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[0;32m   3660\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
            "\u001b[1;31mKeyError\u001b[0m: 0"
          ]
        }
      ],
      "source": [
        "data.shape\n",
        "\n",
        "data[0][0]\n",
        "\n",
        "# p.append(309)\n",
        "# p.append(309)\n",
        "# len(p)\n",
        "# average = 0\n",
        "\n",
        "\n",
        "# for i in range(len(p)):\n",
        "#   p[i] = p[i]//5\n",
        "# for i in range(len(p)):\n",
        "#   average += p[i]\n",
        "# average /= 900\n",
        "# std_deviation = np.std(p)\n",
        "# print(std_deviation, \" \", average)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n6UbucztfXIX",
        "outputId": "7d3782f4-c9fb-40ce-b41b-bfcc3c3f60fd"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[1, 0, 0, ..., 0, 0, 0],\n",
              "       [1, 0, 0, ..., 0, 0, 0],\n",
              "       [1, 0, 0, ..., 0, 0, 0],\n",
              "       ...,\n",
              "       [0, 0, 0, ..., 0, 0, 1],\n",
              "       [0, 0, 0, ..., 0, 0, 1],\n",
              "       [0, 0, 0, ..., 0, 0, 1]])"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "y = np.concatenate([[mapping[i] for i in y]])\n",
        "y\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ixdUuGQbfbuD",
        "outputId": "9e85e32a-6981-419c-fcc9-5960f8ee6932"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(1000, 10)\n"
          ]
        }
      ],
      "source": [
        "print(y.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "MEtlbOyUfeWj"
      },
      "outputs": [],
      "source": [
        "x = x.to_numpy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GyvwgF0pf_k6",
        "outputId": "38d22972-6e2e-48ef-dc59-77c2e5fbf1e9"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "45000"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "x = x[:,:45].reshape(1000,5,9)\n",
        "x.size"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H_mEgTYrhgRR",
        "outputId": "f9c63d84-dc6b-4d9d-9f70-510822d52e07"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[[ 348. , 1016.5,  110.5,   74. ,  183.5],\n",
              "        [ 221. ,   45.5, 1015.5,  122. ,  732. ],\n",
              "        [1019. ,   44.5,   31. , 1015.5,  584.5],\n",
              "        ...,\n",
              "        [  81. ,   32.5, 1015. ,  208. , 1019.5],\n",
              "        [ 490.5,   34.5,   34.5,  995.5, 1000.5],\n",
              "        [ 361. ,   68.5,   37. ,  163.5, 1021.5]],\n",
              "\n",
              "       [[ 206.5, 1015.5,  109. ,   66. ,  152.5],\n",
              "        [ 178. ,   39.5, 1014.5,  129. ,  236. ],\n",
              "        [1018. ,   47.5,   31. ,  783. ,  253.5],\n",
              "        ...,\n",
              "        [  74.5,   31.5, 1014.5,  174. ,  669. ],\n",
              "        [ 326. ,   39.5,   32.5,  750. ,  696.5],\n",
              "        [ 203. ,   63. ,   39. ,   78.5, 1018. ]],\n",
              "\n",
              "       [[ 829. , 1019. ,  127.5,   69. ,   40. ],\n",
              "        [1022.5,   98. ,  789. ,  113.5,   69.5],\n",
              "        [1020. ,   98.5,   33.5, 1015. ,  133. ],\n",
              "        ...,\n",
              "        [ 214. ,   40.5,  912.5,  119. ,   70.5],\n",
              "        [1018. ,   51. ,   32. , 1015. ,  144. ],\n",
              "        [ 591. ,   96. ,   41.5,   32. , 1014.5]],\n",
              "\n",
              "       ...,\n",
              "\n",
              "       [[1018.5, 1015. ,  768.5,  527. ,  136. ],\n",
              "        [ 598. , 1013. , 1012. ,  740. ,  567.5],\n",
              "        [ 913.5,  138.5, 1012.5, 1012. ,  735. ],\n",
              "        ...,\n",
              "        [ 199. , 1012.5, 1012. ,  732. ,  486. ],\n",
              "        [ 788. ,  133.5, 1011. , 1012.5,  733. ],\n",
              "        [ 823.5,  564.5,  134. , 1013. , 1012.5]],\n",
              "\n",
              "       [[1014. , 1014.5,  870. ,  429. ,  101.5],\n",
              "        [ 300. , 1013. , 1012. ,  786. ,  384. ],\n",
              "        [ 714. ,   99.5, 1011.5, 1011. ,  745.5],\n",
              "        ...,\n",
              "        [ 162. , 1011.5, 1011.5,  772. ,  386.5],\n",
              "        [ 629. ,   87.5, 1011. , 1011. ,  708.5],\n",
              "        [ 893. ,  459.5,   91. , 1011. , 1010.5]],\n",
              "\n",
              "       [[1021. , 1019. ,  843.5,  584. ,  159.5],\n",
              "        [ 848.5, 1015. , 1011.5,  828.5,  567. ],\n",
              "        [ 795. ,  265. , 1012.5, 1013.5,  830.5],\n",
              "        ...,\n",
              "        [ 609. , 1012. , 1013.5,  826. ,  490.5],\n",
              "        [ 835. ,  154.5, 1013. , 1012. ,  806.5],\n",
              "        [ 877.5,  507. ,  151.5, 1013. , 1013. ]]])"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "x = x.transpose(0, 2, 1)\n",
        "x = np.nan_to_num(x)\n",
        "x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "--lKgGJghgv2",
        "outputId": "6795bb6a-2988-4c4b-d365-36a714eea288"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(1000, 9, 5)"
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "x.shape\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SLb2eogthwjp",
        "outputId": "f256f4ee-4e6e-48b1-b2b7-36612f86fd15"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " simple_rnn (SimpleRNN)      (None, None, 64)          4480      \n",
            "                                                                 \n",
            " simple_rnn_1 (SimpleRNN)    (None, 64)                8256      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 12736 (49.75 KB)\n",
            "Trainable params: 12736 (49.75 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n",
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense (Dense)               (None, 32)                2080      \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 10)                330       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 2410 (9.41 KB)\n",
            "Trainable params: 2410 (9.41 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n",
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " sequential (Sequential)     (None, 64)                12736     \n",
            "                                                                 \n",
            " sequential_1 (Sequential)   (None, 10)                2410      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 15146 (59.16 KB)\n",
            "Trainable params: 15146 (59.16 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "\n",
        "\n",
        "encoder = models.Sequential([\n",
        "    layers.SimpleRNN(64, return_sequences=True, input_shape=(None, 5)),\n",
        "    layers.SimpleRNN(64)\n",
        "])\n",
        "encoder.summary()\n",
        "\n",
        "decoder = models.Sequential([\n",
        "    layers.Dense(32, activation='relu', input_shape=(64,)),\n",
        "    layers.Dense(10, activation='softmax')\n",
        "])\n",
        "decoder.summary()\n",
        "\n",
        "\n",
        "autoencoder = models.Sequential([\n",
        "    encoder,\n",
        "    decoder\n",
        "])\n",
        "autoencoder.summary()\n",
        "autoencoder.compile(optimizer='adam', loss='mse', metrics=['accuracy'])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YRQTv-uVlGC4",
        "outputId": "b70a0f0b-77d2-48a5-de80-653edc61d16f"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(1000, 9, 5)"
            ]
          },
          "execution_count": 18,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "x.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GZfe-c0SlMm5",
        "outputId": "b99095be-dc16-429d-f350-2ab59ad21e88"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(1000, 10)"
            ]
          },
          "execution_count": 19,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "y.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pCnswisghxGJ",
        "outputId": "249637f0-fa87-47ef-fd2d-4125329aaf0f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/1000\n",
            "13/13 [==============================] - 2s 33ms/step - loss: 0.0875 - accuracy: 0.2075 - val_loss: 0.0820 - val_accuracy: 0.3500\n",
            "Epoch 2/1000\n",
            "13/13 [==============================] - 0s 7ms/step - loss: 0.0728 - accuracy: 0.4800 - val_loss: 0.0692 - val_accuracy: 0.4700\n",
            "Epoch 3/1000\n",
            "13/13 [==============================] - 0s 7ms/step - loss: 0.0587 - accuracy: 0.5825 - val_loss: 0.0571 - val_accuracy: 0.6050\n",
            "Epoch 4/1000\n",
            "13/13 [==============================] - 0s 7ms/step - loss: 0.0467 - accuracy: 0.7100 - val_loss: 0.0465 - val_accuracy: 0.6700\n",
            "Epoch 5/1000\n",
            "13/13 [==============================] - 0s 7ms/step - loss: 0.0362 - accuracy: 0.7638 - val_loss: 0.0379 - val_accuracy: 0.7350\n",
            "Epoch 6/1000\n",
            "13/13 [==============================] - 0s 7ms/step - loss: 0.0277 - accuracy: 0.8225 - val_loss: 0.0310 - val_accuracy: 0.8200\n",
            "Epoch 7/1000\n",
            "13/13 [==============================] - 0s 7ms/step - loss: 0.0211 - accuracy: 0.8863 - val_loss: 0.0247 - val_accuracy: 0.8650\n",
            "Epoch 8/1000\n",
            "13/13 [==============================] - 0s 7ms/step - loss: 0.0161 - accuracy: 0.9275 - val_loss: 0.0204 - val_accuracy: 0.8950\n",
            "Epoch 9/1000\n",
            "13/13 [==============================] - 0s 7ms/step - loss: 0.0124 - accuracy: 0.9388 - val_loss: 0.0171 - val_accuracy: 0.9050\n",
            "Epoch 10/1000\n",
            "13/13 [==============================] - 0s 7ms/step - loss: 0.0102 - accuracy: 0.9513 - val_loss: 0.0157 - val_accuracy: 0.9100\n",
            "Epoch 11/1000\n",
            "13/13 [==============================] - 0s 7ms/step - loss: 0.0083 - accuracy: 0.9600 - val_loss: 0.0145 - val_accuracy: 0.9200\n",
            "Epoch 12/1000\n",
            "13/13 [==============================] - 0s 7ms/step - loss: 0.0069 - accuracy: 0.9712 - val_loss: 0.0132 - val_accuracy: 0.9250\n",
            "Epoch 13/1000\n",
            "13/13 [==============================] - 0s 7ms/step - loss: 0.0061 - accuracy: 0.9712 - val_loss: 0.0135 - val_accuracy: 0.9150\n",
            "Epoch 14/1000\n",
            "13/13 [==============================] - 0s 7ms/step - loss: 0.0054 - accuracy: 0.9750 - val_loss: 0.0119 - val_accuracy: 0.9300\n",
            "Epoch 15/1000\n",
            "13/13 [==============================] - 0s 7ms/step - loss: 0.0047 - accuracy: 0.9750 - val_loss: 0.0115 - val_accuracy: 0.9350\n",
            "Epoch 16/1000\n",
            "13/13 [==============================] - 0s 7ms/step - loss: 0.0041 - accuracy: 0.9775 - val_loss: 0.0120 - val_accuracy: 0.9200\n",
            "Epoch 17/1000\n",
            "13/13 [==============================] - 0s 7ms/step - loss: 0.0037 - accuracy: 0.9812 - val_loss: 0.0115 - val_accuracy: 0.9300\n",
            "Epoch 18/1000\n",
            "13/13 [==============================] - 0s 7ms/step - loss: 0.0033 - accuracy: 0.9837 - val_loss: 0.0113 - val_accuracy: 0.9250\n",
            "Epoch 19/1000\n",
            "13/13 [==============================] - 0s 7ms/step - loss: 0.0030 - accuracy: 0.9850 - val_loss: 0.0116 - val_accuracy: 0.9250\n",
            "Epoch 20/1000\n",
            "13/13 [==============================] - 0s 7ms/step - loss: 0.0029 - accuracy: 0.9837 - val_loss: 0.0113 - val_accuracy: 0.9250\n",
            "Epoch 21/1000\n",
            "13/13 [==============================] - 0s 7ms/step - loss: 0.0028 - accuracy: 0.9850 - val_loss: 0.0114 - val_accuracy: 0.9300\n",
            "Epoch 22/1000\n",
            "13/13 [==============================] - 0s 7ms/step - loss: 0.0027 - accuracy: 0.9862 - val_loss: 0.0113 - val_accuracy: 0.9250\n",
            "Epoch 23/1000\n",
            "13/13 [==============================] - 0s 7ms/step - loss: 0.0024 - accuracy: 0.9862 - val_loss: 0.0115 - val_accuracy: 0.9250\n",
            "Epoch 24/1000\n",
            "13/13 [==============================] - 0s 10ms/step - loss: 0.0025 - accuracy: 0.9825 - val_loss: 0.0117 - val_accuracy: 0.9300\n",
            "Epoch 25/1000\n",
            "13/13 [==============================] - 0s 7ms/step - loss: 0.0023 - accuracy: 0.9862 - val_loss: 0.0113 - val_accuracy: 0.9250\n",
            "Epoch 26/1000\n",
            "13/13 [==============================] - 0s 7ms/step - loss: 0.0022 - accuracy: 0.9862 - val_loss: 0.0113 - val_accuracy: 0.9250\n",
            "Epoch 27/1000\n",
            "13/13 [==============================] - 0s 7ms/step - loss: 0.0021 - accuracy: 0.9887 - val_loss: 0.0115 - val_accuracy: 0.9200\n",
            "Epoch 28/1000\n",
            "13/13 [==============================] - 0s 7ms/step - loss: 0.0021 - accuracy: 0.9887 - val_loss: 0.0111 - val_accuracy: 0.9250\n",
            "Epoch 29/1000\n",
            "13/13 [==============================] - 0s 7ms/step - loss: 0.0020 - accuracy: 0.9862 - val_loss: 0.0110 - val_accuracy: 0.9250\n",
            "Epoch 30/1000\n",
            "13/13 [==============================] - 0s 7ms/step - loss: 0.0020 - accuracy: 0.9887 - val_loss: 0.0108 - val_accuracy: 0.9250\n",
            "Epoch 31/1000\n",
            "13/13 [==============================] - 0s 7ms/step - loss: 0.0019 - accuracy: 0.9887 - val_loss: 0.0107 - val_accuracy: 0.9300\n",
            "Epoch 32/1000\n",
            "13/13 [==============================] - 0s 7ms/step - loss: 0.0018 - accuracy: 0.9887 - val_loss: 0.0109 - val_accuracy: 0.9300\n",
            "Epoch 33/1000\n",
            "13/13 [==============================] - 0s 7ms/step - loss: 0.0018 - accuracy: 0.9887 - val_loss: 0.0107 - val_accuracy: 0.9300\n",
            "Epoch 34/1000\n",
            "13/13 [==============================] - 0s 7ms/step - loss: 0.0018 - accuracy: 0.9887 - val_loss: 0.0109 - val_accuracy: 0.9300\n",
            "Epoch 35/1000\n",
            "13/13 [==============================] - 0s 7ms/step - loss: 0.0017 - accuracy: 0.9887 - val_loss: 0.0106 - val_accuracy: 0.9300\n",
            "Epoch 36/1000\n",
            "13/13 [==============================] - 0s 7ms/step - loss: 0.0017 - accuracy: 0.9887 - val_loss: 0.0109 - val_accuracy: 0.9300\n",
            "Epoch 37/1000\n",
            "13/13 [==============================] - 0s 7ms/step - loss: 0.0016 - accuracy: 0.9900 - val_loss: 0.0107 - val_accuracy: 0.9300\n",
            "Epoch 38/1000\n",
            "13/13 [==============================] - 0s 7ms/step - loss: 0.0016 - accuracy: 0.9875 - val_loss: 0.0105 - val_accuracy: 0.9250\n",
            "Epoch 39/1000\n",
            "13/13 [==============================] - 0s 7ms/step - loss: 0.0017 - accuracy: 0.9862 - val_loss: 0.0108 - val_accuracy: 0.9250\n",
            "Epoch 40/1000\n",
            "13/13 [==============================] - 0s 7ms/step - loss: 0.0016 - accuracy: 0.9900 - val_loss: 0.0108 - val_accuracy: 0.9300\n",
            "Epoch 41/1000\n",
            "13/13 [==============================] - 0s 7ms/step - loss: 0.0016 - accuracy: 0.9900 - val_loss: 0.0106 - val_accuracy: 0.9250\n",
            "Epoch 42/1000\n",
            "13/13 [==============================] - 0s 7ms/step - loss: 0.0016 - accuracy: 0.9900 - val_loss: 0.0108 - val_accuracy: 0.9250\n",
            "Epoch 43/1000\n",
            "13/13 [==============================] - 0s 7ms/step - loss: 0.0015 - accuracy: 0.9900 - val_loss: 0.0107 - val_accuracy: 0.9250\n",
            "Epoch 44/1000\n",
            "13/13 [==============================] - 0s 7ms/step - loss: 0.0015 - accuracy: 0.9900 - val_loss: 0.0106 - val_accuracy: 0.9250\n",
            "Epoch 45/1000\n",
            "13/13 [==============================] - 0s 7ms/step - loss: 0.0015 - accuracy: 0.9900 - val_loss: 0.0108 - val_accuracy: 0.9250\n",
            "Epoch 46/1000\n",
            "13/13 [==============================] - 0s 8ms/step - loss: 0.0015 - accuracy: 0.9900 - val_loss: 0.0108 - val_accuracy: 0.9250\n",
            "Epoch 47/1000\n",
            "13/13 [==============================] - 0s 10ms/step - loss: 0.0015 - accuracy: 0.9900 - val_loss: 0.0111 - val_accuracy: 0.9250\n",
            "Epoch 48/1000\n",
            "13/13 [==============================] - 0s 7ms/step - loss: 0.0015 - accuracy: 0.9900 - val_loss: 0.0109 - val_accuracy: 0.9250\n",
            "Epoch 49/1000\n",
            "13/13 [==============================] - 0s 7ms/step - loss: 0.0014 - accuracy: 0.9900 - val_loss: 0.0108 - val_accuracy: 0.9250\n",
            "Epoch 50/1000\n",
            "13/13 [==============================] - 0s 7ms/step - loss: 0.0015 - accuracy: 0.9900 - val_loss: 0.0106 - val_accuracy: 0.9250\n",
            "Epoch 51/1000\n",
            "13/13 [==============================] - 0s 7ms/step - loss: 0.0014 - accuracy: 0.9900 - val_loss: 0.0109 - val_accuracy: 0.9250\n",
            "Epoch 52/1000\n",
            "13/13 [==============================] - 0s 7ms/step - loss: 0.0015 - accuracy: 0.9900 - val_loss: 0.0110 - val_accuracy: 0.9300\n",
            "Epoch 53/1000\n",
            "13/13 [==============================] - 0s 7ms/step - loss: 0.0014 - accuracy: 0.9900 - val_loss: 0.0110 - val_accuracy: 0.9300\n",
            "Epoch 54/1000\n",
            "13/13 [==============================] - 0s 7ms/step - loss: 0.0014 - accuracy: 0.9900 - val_loss: 0.0109 - val_accuracy: 0.9250\n",
            "Epoch 55/1000\n",
            "13/13 [==============================] - 0s 7ms/step - loss: 0.0014 - accuracy: 0.9900 - val_loss: 0.0108 - val_accuracy: 0.9300\n",
            "Epoch 56/1000\n",
            "13/13 [==============================] - 0s 8ms/step - loss: 0.0014 - accuracy: 0.9900 - val_loss: 0.0109 - val_accuracy: 0.9300\n",
            "Epoch 57/1000\n",
            "13/13 [==============================] - 0s 7ms/step - loss: 0.0014 - accuracy: 0.9900 - val_loss: 0.0110 - val_accuracy: 0.9250\n",
            "Epoch 58/1000\n",
            "13/13 [==============================] - 0s 7ms/step - loss: 0.0014 - accuracy: 0.9900 - val_loss: 0.0111 - val_accuracy: 0.9300\n",
            "Epoch 59/1000\n",
            "13/13 [==============================] - 0s 7ms/step - loss: 0.0014 - accuracy: 0.9900 - val_loss: 0.0110 - val_accuracy: 0.9300\n",
            "Epoch 60/1000\n",
            "13/13 [==============================] - 0s 7ms/step - loss: 0.0014 - accuracy: 0.9900 - val_loss: 0.0110 - val_accuracy: 0.9300\n",
            "Epoch 61/1000\n",
            "13/13 [==============================] - 0s 7ms/step - loss: 0.0014 - accuracy: 0.9900 - val_loss: 0.0109 - val_accuracy: 0.9250\n",
            "Epoch 62/1000\n",
            "13/13 [==============================] - 0s 7ms/step - loss: 0.0015 - accuracy: 0.9900 - val_loss: 0.0110 - val_accuracy: 0.9250\n",
            "Epoch 63/1000\n",
            "13/13 [==============================] - 0s 7ms/step - loss: 0.0014 - accuracy: 0.9900 - val_loss: 0.0112 - val_accuracy: 0.9300\n",
            "Epoch 64/1000\n",
            "13/13 [==============================] - 0s 7ms/step - loss: 0.0014 - accuracy: 0.9900 - val_loss: 0.0111 - val_accuracy: 0.9300\n",
            "Epoch 65/1000\n",
            "13/13 [==============================] - 0s 7ms/step - loss: 0.0014 - accuracy: 0.9900 - val_loss: 0.0112 - val_accuracy: 0.9300\n",
            "Epoch 66/1000\n",
            "13/13 [==============================] - 0s 9ms/step - loss: 0.0014 - accuracy: 0.9900 - val_loss: 0.0111 - val_accuracy: 0.9300\n",
            "Epoch 67/1000\n",
            "13/13 [==============================] - 0s 7ms/step - loss: 0.0014 - accuracy: 0.9900 - val_loss: 0.0110 - val_accuracy: 0.9250\n",
            "Epoch 68/1000\n",
            "13/13 [==============================] - 0s 7ms/step - loss: 0.0014 - accuracy: 0.9900 - val_loss: 0.0110 - val_accuracy: 0.9250\n",
            "Epoch 69/1000\n",
            "13/13 [==============================] - 0s 7ms/step - loss: 0.0014 - accuracy: 0.9900 - val_loss: 0.0110 - val_accuracy: 0.9300\n",
            "Epoch 70/1000\n",
            "13/13 [==============================] - 0s 8ms/step - loss: 0.0014 - accuracy: 0.9900 - val_loss: 0.0111 - val_accuracy: 0.9300\n",
            "Epoch 71/1000\n",
            "13/13 [==============================] - 0s 7ms/step - loss: 0.0014 - accuracy: 0.9875 - val_loss: 0.0110 - val_accuracy: 0.9300\n",
            "Epoch 72/1000\n",
            "13/13 [==============================] - 0s 7ms/step - loss: 0.0014 - accuracy: 0.9900 - val_loss: 0.0110 - val_accuracy: 0.9300\n",
            "Epoch 73/1000\n",
            "13/13 [==============================] - 0s 7ms/step - loss: 0.0014 - accuracy: 0.9900 - val_loss: 0.0110 - val_accuracy: 0.9300\n",
            "Epoch 74/1000\n",
            "13/13 [==============================] - 0s 7ms/step - loss: 0.0014 - accuracy: 0.9900 - val_loss: 0.0112 - val_accuracy: 0.9300\n",
            "Epoch 75/1000\n",
            "13/13 [==============================] - 0s 7ms/step - loss: 0.0014 - accuracy: 0.9900 - val_loss: 0.0113 - val_accuracy: 0.9300\n",
            "Epoch 76/1000\n",
            "13/13 [==============================] - 0s 7ms/step - loss: 0.0014 - accuracy: 0.9900 - val_loss: 0.0112 - val_accuracy: 0.9300\n",
            "Epoch 77/1000\n",
            "13/13 [==============================] - 0s 7ms/step - loss: 0.0014 - accuracy: 0.9900 - val_loss: 0.0113 - val_accuracy: 0.9300\n",
            "Epoch 78/1000\n",
            "13/13 [==============================] - 0s 7ms/step - loss: 0.0014 - accuracy: 0.9900 - val_loss: 0.0112 - val_accuracy: 0.9300\n",
            "Epoch 79/1000\n",
            "13/13 [==============================] - 0s 7ms/step - loss: 0.0014 - accuracy: 0.9900 - val_loss: 0.0112 - val_accuracy: 0.9300\n",
            "Epoch 80/1000\n",
            "13/13 [==============================] - 0s 7ms/step - loss: 0.0014 - accuracy: 0.9900 - val_loss: 0.0112 - val_accuracy: 0.9300\n",
            "Epoch 81/1000\n",
            "13/13 [==============================] - 0s 7ms/step - loss: 0.0014 - accuracy: 0.9900 - val_loss: 0.0112 - val_accuracy: 0.9300\n",
            "Epoch 82/1000\n",
            "13/13 [==============================] - 0s 7ms/step - loss: 0.0014 - accuracy: 0.9900 - val_loss: 0.0113 - val_accuracy: 0.9300\n",
            "Epoch 83/1000\n",
            "13/13 [==============================] - 0s 7ms/step - loss: 0.0014 - accuracy: 0.9900 - val_loss: 0.0113 - val_accuracy: 0.9300\n",
            "Epoch 84/1000\n",
            "13/13 [==============================] - 0s 7ms/step - loss: 0.0014 - accuracy: 0.9900 - val_loss: 0.0112 - val_accuracy: 0.9300\n",
            "Epoch 85/1000\n",
            "13/13 [==============================] - 0s 9ms/step - loss: 0.0014 - accuracy: 0.9900 - val_loss: 0.0113 - val_accuracy: 0.9300\n",
            "Epoch 86/1000\n",
            "13/13 [==============================] - 0s 8ms/step - loss: 0.0014 - accuracy: 0.9900 - val_loss: 0.0112 - val_accuracy: 0.9300\n",
            "Epoch 87/1000\n",
            "13/13 [==============================] - 0s 7ms/step - loss: 0.0014 - accuracy: 0.9900 - val_loss: 0.0111 - val_accuracy: 0.9350\n",
            "Epoch 88/1000\n",
            "13/13 [==============================] - 0s 7ms/step - loss: 0.0014 - accuracy: 0.9900 - val_loss: 0.0114 - val_accuracy: 0.9300\n",
            "Epoch 89/1000\n",
            "13/13 [==============================] - 0s 7ms/step - loss: 0.0014 - accuracy: 0.9900 - val_loss: 0.0113 - val_accuracy: 0.9350\n",
            "Epoch 90/1000\n",
            "13/13 [==============================] - 0s 7ms/step - loss: 0.0014 - accuracy: 0.9900 - val_loss: 0.0113 - val_accuracy: 0.9350\n",
            "Epoch 91/1000\n",
            "13/13 [==============================] - 0s 7ms/step - loss: 0.0014 - accuracy: 0.9900 - val_loss: 0.0113 - val_accuracy: 0.9350\n",
            "Epoch 92/1000\n",
            " 1/13 [=>............................] - ETA: 0s - loss: 0.0019 - accuracy: 0.9844"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[20], line 5\u001b[0m\n\u001b[0;32m      2\u001b[0m epochs \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1000\u001b[39m\n\u001b[0;32m      4\u001b[0m x_train, x_val, y_train, y_val \u001b[38;5;241m=\u001b[39m train_test_split(x, y, test_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.2\u001b[39m, random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m)\n\u001b[1;32m----> 5\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[43mautoencoder\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      6\u001b[0m \u001b[43m                \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mepochs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      7\u001b[0m \u001b[43m                \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      8\u001b[0m \u001b[43m                \u001b[49m\u001b[43mshuffle\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m      9\u001b[0m \u001b[43m                \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mx_val\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_val\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     11\u001b[0m autoencoder\u001b[38;5;241m.\u001b[39mevaluate(x_val, y_val)\n",
            "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\keras\\src\\utils\\traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     63\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     66\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
            "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\keras\\src\\engine\\training.py:1742\u001b[0m, in \u001b[0;36mModel.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1734\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mexperimental\u001b[38;5;241m.\u001b[39mTrace(\n\u001b[0;32m   1735\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   1736\u001b[0m     epoch_num\u001b[38;5;241m=\u001b[39mepoch,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1739\u001b[0m     _r\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[0;32m   1740\u001b[0m ):\n\u001b[0;32m   1741\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[1;32m-> 1742\u001b[0m     tmp_logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1743\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39mshould_sync:\n\u001b[0;32m   1744\u001b[0m         context\u001b[38;5;241m.\u001b[39masync_wait()\n",
            "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
            "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:825\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    822\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    824\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[1;32m--> 825\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    827\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[0;32m    828\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
            "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:857\u001b[0m, in \u001b[0;36mFunction._call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    854\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[0;32m    855\u001b[0m   \u001b[38;5;66;03m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[0;32m    856\u001b[0m   \u001b[38;5;66;03m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[1;32m--> 857\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_no_variable_creation_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# pylint: disable=not-callable\u001b[39;00m\n\u001b[0;32m    858\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_variable_creation_fn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    859\u001b[0m   \u001b[38;5;66;03m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[0;32m    860\u001b[0m   \u001b[38;5;66;03m# in parallel.\u001b[39;00m\n\u001b[0;32m    861\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n",
            "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\tracing_compiler.py:148\u001b[0m, in \u001b[0;36mTracingCompiler.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    145\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[0;32m    146\u001b[0m   (concrete_function,\n\u001b[0;32m    147\u001b[0m    filtered_flat_args) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[1;32m--> 148\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mconcrete_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    149\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfiltered_flat_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconcrete_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\monomorphic_function.py:1349\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[1;34m(self, args, captured_inputs)\u001b[0m\n\u001b[0;32m   1345\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[0;32m   1346\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[0;32m   1347\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[0;32m   1348\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[1;32m-> 1349\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_call_outputs(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m   1350\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[0;32m   1351\u001b[0m     args,\n\u001b[0;32m   1352\u001b[0m     possible_gradient_type,\n\u001b[0;32m   1353\u001b[0m     executing_eagerly)\n\u001b[0;32m   1354\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
            "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\atomic_function.py:196\u001b[0m, in \u001b[0;36mAtomicFunction.__call__\u001b[1;34m(self, *args)\u001b[0m\n\u001b[0;32m    194\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m record\u001b[38;5;241m.\u001b[39mstop_recording():\n\u001b[0;32m    195\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mexecuting_eagerly():\n\u001b[1;32m--> 196\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_bound_context\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    197\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    198\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    199\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunction_type\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflat_outputs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    200\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    201\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    202\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m make_call_op_in_graph(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28mlist\u001b[39m(args))\n",
            "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\tensorflow\\python\\eager\\context.py:1457\u001b[0m, in \u001b[0;36mContext.call_function\u001b[1;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[0;32m   1455\u001b[0m cancellation_context \u001b[38;5;241m=\u001b[39m cancellation\u001b[38;5;241m.\u001b[39mcontext()\n\u001b[0;32m   1456\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cancellation_context \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 1457\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1458\u001b[0m \u001b[43m      \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mutf-8\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1459\u001b[0m \u001b[43m      \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1460\u001b[0m \u001b[43m      \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtensor_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1461\u001b[0m \u001b[43m      \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1462\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1463\u001b[0m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1464\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1465\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[0;32m   1466\u001b[0m       name\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m   1467\u001b[0m       num_outputs\u001b[38;5;241m=\u001b[39mnum_outputs,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1471\u001b[0m       cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_context,\n\u001b[0;32m   1472\u001b[0m   )\n",
            "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\tensorflow\\python\\eager\\execute.py:53\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     51\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     52\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 53\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     54\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     55\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     56\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
            "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "\n",
        "batch_size = 64\n",
        "epochs = 1000\n",
        "\n",
        "x_train, x_val, y_train, y_val = train_test_split(x, y, test_size=0.2, random_state=42)\n",
        "history = autoencoder.fit(x_train, y_train,\n",
        "                epochs=epochs,\n",
        "                batch_size=batch_size,\n",
        "                shuffle=True,\n",
        "                validation_data=(x_val, y_val))\n",
        "\n",
        "autoencoder.evaluate(x_val, y_val)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 472
        },
        "id": "P7fhMJLunvIv",
        "outputId": "f536fcd7-31b3-4a4d-8dfa-ea0929927b2e"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "plt.plot(history.history[\"loss\"], label=\"Training loss\")\n",
        "plt.plot(history.history[\"accuracy\"], label=\"Training accuracy\")\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.ylabel(\"Value\")\n",
        "plt.title(\"RNN Training Results\")\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 176
        },
        "id": "Qd6bb3vCHs7G",
        "outputId": "ef790666-4cb7-4e3e-dea5-a60c79c4013d"
      },
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-17-9585e56969a8>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprediction_array\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'prediction_array' is not defined"
          ]
        }
      ],
      "source": [
        "prediction_array"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iyGPyvGpIWuE"
      },
      "outputs": [],
      "source": [
        "\n",
        "min_val = 0\n",
        "index = -1\n",
        "for i in range(0,len(prediction_array)):\n",
        "    if prediction_array[i] > min_val:\n",
        "        min_val = prediction_array[i]\n",
        "        index = i\n",
        "\n",
        "print(prediction_array, \"    \", index)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wB7pbyCiIhj5",
        "outputId": "d4fe65ca-619a-46bf-9b35-76e448b0fcbc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1/1 [==============================] - 0s 30ms/step\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "array([[8.7467182e-01, 2.6363975e-04, 4.9550671e-02, 3.2109339e-03,\n",
              "        2.8106472e-02, 2.9162439e-03, 3.3222035e-02, 3.4205662e-03,\n",
              "        4.6376819e-03]], dtype=float32)"
            ]
          },
          "execution_count": 23,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "autoencoder.predict(x[:1])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lD5gAO4xIr-u"
      },
      "outputs": [],
      "source": [
        "autoencoder.save('/content/EETrainedModel32_batchSize.keras')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XLbJ_bP738sw",
        "outputId": "8d3c5b61-6191-4be9-99bc-21ed9568a4c1"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "1"
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "array = [[1,2],[1,2]]\n",
        "array[0][0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UyxeZWiGKVbE",
        "outputId": "8902ab13-f6b8-49cd-8583-812544c7b5e6"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[[1, 2], [1, 2]]"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "array[:]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 176
        },
        "id": "rl0uPcu54ESU",
        "outputId": "04325a31-63f2-4aa6-cbe3-78deb556b511"
      },
      "outputs": [
        {
          "ename": "TypeError",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-5-d819a1cd5e8a>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0marray\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m: list indices must be integers or slices, not tuple"
          ]
        }
      ],
      "source": [
        "array[:,0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ppp6rDWL4H9R"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
